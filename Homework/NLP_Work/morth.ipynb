{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Vadim/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Vadim/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"book1857_ok.txt\", \"book1863_ok.txt\", \"book1873_ok.txt\", \"book1876_ok.txt\", \"book1882_ok.txt\", \"book1887_ok.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity = []\n",
    "pos_counts = []\n",
    "most_common_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анализ для файла book1857_ok.txt:\n",
      "Лексическое разнообразие: 0.1714166431316691\n",
      "Количество частей речи: <FreqDist with 22 samples and 81439 outcomes>\n",
      "Самые встречающиеся слова: [('это', 1101), ('говорить', 806), ('который', 633), ('свой', 570), ('сказать', 550), ('дело', 544), ('знать', 488), ('ваш', 484), ('такой', 449), ('человек', 429)]\n",
      "\n",
      "\n",
      "Анализ для файла book1863_ok.txt:\n",
      "Лексическое разнообразие: 0.38459760818071526\n",
      "Количество частей речи: <FreqDist with 20 samples and 17309 outcomes>\n",
      "Самые встречающиеся слова: [('это', 200), ('который', 158), ('говорить', 133), ('свой', 112), ('сказать', 110), ('трифонович', 98), ('кондратий', 92), ('ваш', 86), ('человек', 72), ('наш', 72)]\n",
      "\n",
      "\n",
      "Анализ для файла book1873_ok.txt:\n",
      "Лексическое разнообразие: 0.18329180398145917\n",
      "Количество частей речи: <FreqDist with 26 samples and 74646 outcomes>\n",
      "Самые встречающиеся слова: [('который', 823), ('это', 793), ('свой', 483), ('человек', 455), ('время', 382), ('говорить', 369), ('один', 365), ('наш', 353), ('дело', 349), ('сказать', 332)]\n",
      "\n",
      "\n",
      "Анализ для файла book1876_ok.txt:\n",
      "Лексическое разнообразие: 0.16880289950019547\n",
      "Количество частей речи: <FreqDist with 25 samples and 94637 outcomes>\n",
      "Самые встречающиеся слова: [('это', 1348), ('который', 1094), ('свой', 652), ('говорить', 647), ('сказать', 627), ('человек', 509), ('один', 492), ('дело', 447), ('время', 407), ('знать', 405)]\n",
      "\n",
      "\n",
      "Анализ для файла book1882_ok.txt:\n",
      "Лексическое разнообразие: 0.22371754642865443\n",
      "Количество частей речи: <FreqDist with 16 samples and 43023 outcomes>\n",
      "Самые встречающиеся слова: [('это', 566), ('который', 486), ('человек', 248), ('сказать', 247), ('говорить', 242), ('свой', 228), ('время', 221), ('один', 207), ('такой', 204), ('знать', 167)]\n",
      "\n",
      "\n",
      "Анализ для файла book1887_ok.txt:\n",
      "Лексическое разнообразие: 0.19406318260359273\n",
      "Количество частей речи: <FreqDist with 20 samples and 61346 outcomes>\n",
      "Самые встречающиеся слова: [('который', 650), ('это', 577), ('свой', 465), ('время', 349), ('говорить', 309), ('сказать', 278), ('человек', 272), ('один', 263), ('такой', 244), ('дело', 244)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r') as file:\n",
    "        book = file.read()\n",
    "    \n",
    "    # Токенизация текста\n",
    "    words = word_tokenize(book, language='russian')\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
    "    \n",
    "    # Лемматизация\n",
    "    lemmatized_words = [morph.parse(word)[0].normal_form for word in filtered_words]\n",
    "        \n",
    "    # Разметка слов\n",
    "    tagged = pos_tag(lemmatized_words)\n",
    "    \n",
    "    # Вычисляем лексическое разнообразие\n",
    "    lexical_diversity.append(len(set(lemmatized_words)) / len(lemmatized_words))\n",
    "    \n",
    "    # Считаем количество определенных частей речи\n",
    "    pos_counts.append(FreqDist(tag for (word, tag) in tagged))\n",
    "    \n",
    "    # Считаем самые встречающиеся слова\n",
    "    fdist = FreqDist(lemmatized_words)\n",
    "    most_common_words.append(fdist.most_common(10))\n",
    "\n",
    "# Выводим результаты анализа для каждого файла\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    print(f\"Анализ для файла {file_path}:\")\n",
    "    print(f\"Лексическое разнообразие: {lexical_diversity[i]}\")\n",
    "    print(f\"Количество частей речи: {pos_counts[i]}\")\n",
    "    print(f\"Самые встречающиеся слова: {most_common_words[i]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
